import torch
import torch.optim as optim
import numpy as np
from torch import nn
import os
from PIL import Image

def conceptual_counterfactual(embedding: torch.Tensor, label: torch.Tensor, concept_bank: 'ConceptBank', model_top: nn.Module,
                                tau: float = 1e-3, mu1: float = 1e-4,
                               mu2: float = 1e-4,
                               n_steps: int = 200, step_size: float = 0.01, momentum: float = 0.9):
    """
    Generating conceptual counterfactual explanations based on constrained perturbation.

    Args:
        embedding (torch.Tensor): The embedding of the image to explain, typically generated by the model.
        label (torch.Tensor): The label of the image to explain, used for evaluation of success.
        concept_bank (ConceptBank): An instance of ConceptBank that contains concept vectors and their margin information.
        model_top (nn.Module): The top layers of the model used for predictions on the embeddings.
        tau (float, optional): The threshold for clamping the difference between predictions. Defaults to 1e-3.
        mu1 (float, optional): Coefficient for L1 regularization on Wx. Defaults to 1e-4.
        mu2 (float, optional): Coefficient for L2 regularization on Wy. Defaults to 1e-4.
        n_steps (int, optional): The maximum number of iterations for optimization. Defaults to 200.
        step_size (float, optional): The learning rate for the optimizer. Defaults to 0.01.
        momentum (float, optional): The momentum factor for the optimizer. Defaults to 0.9.

    Returns:
        dict: A dictionary containing the results of the counterfactual generation, including:
            "success": bool: Indicates whether the counterfactual was successfully generated.
            "selected_superpixels": dict: A dictionary with keys 'pos' and 'neg' containing selected superpixels for positive and negative concepts, respectively.
            "concept_scores": dict: A mapping of concept names to their corresponding scores.
            "perturbed_embedding": np.ndarray: The perturbed embedding after optimization.
    """
    # Initial model prediction logit (gpre)
    gpre = model_top(embedding).squeeze()

    # Concept and weight initialization
    concepts = concept_bank.vectors.to(embedding.device)

    # Initialize perturbation weight matrix W with requires_grad=True for optimization
    Wx = nn.Parameter(torch.zeros(concepts.shape[0], device=embedding.device), requires_grad=True)
    Wy = nn.Parameter(torch.zeros(concepts.shape[0], device=embedding.device), requires_grad=True)

    optimizer = optim.SGD([Wx, Wy], lr=step_size, momentum=momentum)

    # Iteratively optimize the weight matrix W based on constrained objective
    for _ in range(n_steps):
        optimizer.zero_grad()

        # Perturbation within the feature space (Î¶ in equation)
        perturbation = Wx.unsqueeze(1) * concepts + Wy.unsqueeze(1) * concepts
        perturbed_embedding = embedding + perturbation.sum(dim=0)

        # Model prediction on perturbed embedding (galt)
        galt = model_top(perturbed_embedding).squeeze()

        # Define the constrained loss function
        g_diff = torch.clamp(gpre - galt, min=-tau)  # Ensure the difference is constrained
        l1_loss = mu1 * Wx.abs().sum()  # L1 regularization on Wx
        l2_loss = mu2 * Wy.norm(2)  # L2 regularization on Wy
        loss = -g_diff + l1_loss + l2_loss  # Note the negative sign for maximizing g_diff

        # Backpropagation and gradient update
        loss.backward()
        optimizer.step()

        # Clamp W to enforce constraints
        Wx.data = torch.clamp(Wx.data, min=-1, max=0)  # Wx constraints for negative factors
        Wy.data = torch.clamp(Wy.data, min=0, max=1)  # Wy constraints for positive factors

    # Collect the optimized weights and concept scores for explanation
    Wy_final = Wy.detach().cpu().numpy()
    selected_concepts_pos = [concept for concept, weight in zip(concept_bank.concept_names, Wy_final) if weight == 1]
    selected_concepts_neg = [concept for concept, weight in zip(concept_bank.concept_names, Wy_final) if weight == -1]

    # Store the selected superpixels
    selected_superpixels = {
        "pos": [],
        "neg": []
    }

    if selected_concepts_pos:
        for concept in selected_concepts_pos:
            selected_superpixels["pos"].append(get_superpixel_from_concept(concept, concept_bank, "pos"))

    if selected_concepts_neg:
        for concept in selected_concepts_neg:
            selected_superpixels["neg"].append(get_superpixel_from_concept(concept, concept_bank, "neg"))

    return {
        "success": (galt.argmax() == label.item()),
        "selected_superpixels": selected_superpixels,  # Returns the selected superpixels
        "concept_scores": {concept: weight for concept, weight in zip(concept_bank.concept_names, Wy_final)},
        "perturbed_embedding": perturbed_embedding.detach().cpu().numpy()
    }

def get_superpixel_from_concept(concept_name, concept_bank, folder):
    """Superpixels are obtained according to the concept name and saved in the specified folder"""
    concept_folder = os.path.join(concept_bank.base_path, concept_name)
    superpixel_files = [f for f in os.listdir(concept_folder) if f.endswith('.png')]

    if superpixel_files:
        # Select a superpixel file at random
        selected_file = np.random.choice(superpixel_files)
        superpixel_image = Image.open(os.path.join(concept_folder, selected_file))

        # Save the selected superpixel in the designated folder
        output_folder = os.path.join(concept_bank.base_path, folder)
        os.makedirs(output_folder, exist_ok=True)
        output_path = os.path.join(output_folder, f'{concept_name}_superpixel.png')
        superpixel_image.save(output_path)  # Save the superpixel image
        return superpixel_image
    return None
